# functions for CESI - to calculate trends and identify outliers
#  1) mk_test
#  2) hurdle_test
#  3) negbin_test
#  4) stationarity_test
#  5) identify_trends < calls on tests 2, 3 & 4
#  6) find_outliers
#  7) ex_stn_trend_stats


#--------------------------------------------------
#1) mk_test
#'
#' @description
#' mk_test performs a Mann-Kendall Test and return multiple test statistics given a
#' variable y and a variable x in vector form.
#'
#' @param y_var a vector of numbers representing the y variable
#' @param x_var a vector of numbers representing the x variable
#' @param z_low a numeric representing the z-value for the lower confidence level,
#' defaulted to 0.52 representing the 70 percent confidence threshold
#' @param z_high a numeric representing the z-value for the upper confidence level,
#' defaulted to 1.28 representing the 90 percent confidence threshold
#' @param keep_z a boolean for whether or not z-value will be included,
#' defaulted to FALSE
#'
#' @return a dataframe of the form || slope || intercept || ConfidenceLevel || z_value ||
#'
#' @details
#'1. y and x variables should have equal length
#'2. Although the function does allow input y to contain duplicates of a certain value,
#'   please take into account that an excess amount of duplicates within y will likely
#'   decrease the accuracy of the result generated by the Mann-Kendall test. For data
#'   set with too many ties in the dependent variable, consider testing for the trend
#'   using alternative methods, such as generalized linear model. Refer to other functions
#'   such as hurdle_test and negbin below for more information.
#'
#' @export
mk_test <-function(y_var, x_var, z_low=0.52, z_high=1.28, keep_z=FALSE){
  sen <- zyp.sen(y_var~x_var)
  slope <- round(sen$coefficients[[2]],2)
  intercept <- round(sen$coefficients[[1]],2)
  corr<- cor.test(y_var, x_var, method = "kendall", alternative = "two.sided", exact = FALSE)
  Z <-abs(corr$statistic[["z"]])
  CATTrend <- case_when(Z>=z_high ~ "Confident",
                        Z>=z_low & Z<z_high ~ "Likely",
                        Z<z_low ~ "Uncertain")
  years.for.trend <<- sum(!is.na(y_var))
  ret<- data.frame(slope=slope,intercept=intercept,CATTrend=CATTrend,
                   years.for.trend=years.for.trend,z_value=Z)
  if(!keep_z){
    ret <- ret %>% dplyr::select(-z_value)
  }
  return(ret)
}

#--------------------------------------------------
#2) hurdle_test
#'
#' @description
#' hurdle_test performs a hurdle test and returns multiple test statistics given
#' a variable y and a variable x. Hurdle test can be used to fit a linear model
#' when a data set contains an excess amount of zeros.
#'
#' @param y_var a vector of numbers representing the y variable
#' @param x_var a vector of numbers representing the x variable
#' @param zero_fam a character string representing the model family for the zero
#' portion of the data. Defaulted to "binomial" indicating binomial family
#' @param count_dist a character string representing the count distribution.
#' Defaulted to 'negbin', the negative binomial distribution
#' @param zero_dist a character string representing the zero distribution.
#' Defaulted to "binomial", the binomial distribution
#' @param link a character string representing the link for binomial zero hurdle
#' model. Defaulted to 'logit', the logarithm function
#'
#' @return a dataframe of the form || slope || intercept || ConfidenceLevel || Test type,
#' or a character string if the test is not applicable;
#'
#' @details
#' The hurdle test deals with zero and non-zero portions separatly using two
#' different models: the negative binomial distribution for the non-zero portion
#' and the binomial distribution for the zero portion. Confidence intervals are
#' created to report the level of confidence in the trend detected. A generalized
#' linear model (glm) will be then established between the two distributions with
#' a logarithm link function. The slope and intercept of the resulting model will
#' be recorded and returned.
#' Things to take notice of:
#' 1. y and x variables need to have the same length
#' 2. Although the detail section only describes the condition with a negative
#'    binomial count distribution and a binomial zero distribution, this function
#'    can be used for other distributions as well.
#' 3. Do note that this function does not check for the accuracy of the fitted
#'    model, neither does it provide any recommendations on what distribution
#'    fits the best. In order to use other families, it is highly suggested to
#'    look at the concept of general linear models beforehand.
#' 4. The program will return an error if the y variable does not contain any zeros.
#'    In order to calculate the trend using this function, make sure that there
#'    is at least one zero value in the y variable. If the error message "Data
#'    cannot be fitted using hurdle model" appears, user might want to consider
#'    using negative binomial model (provided as the negbin() function in the
#'    same package) for cases with excess amount of zeros, or Mann-Kendall Test
#'    for cases with limited ties and zeros.
#'
#' @export
hurdle_test <- function(y_var, x_var, zero_fam="binomial", count_dist="negbin",
                        zero_dist="binomial", link="logit"){
  # Are we confident there is a trend?
  # Count portion of hurdle
  y_count <- y_var[y_var>0]
  x_count <- x_var[y_var>0]
  model.count <- tryCatch(MASS::glm.nb(y_count~x_count),
                          error=function(e){return("A")})
  profile.count <- tryCatch(profile(model.count), error=function(e){return("A")})
  low.c<- ifelse(is.character(model.count)|is.character(profile.count), NA, exp(confint(profile.count, level=0.9))[2,1])
  hi.c <- ifelse(is.character(model.count)|is.character(profile.count), NA, exp(confint(profile.count, level=0.9))[2,2])
  # Zero portion of hurdle
  zero_indicator <- !I(y_var==0)
  model.zero <- tryCatch(glm(zero_indicator~x_var, family=zero_fam),
                         error=function(e){return("A")})
  profile.zero <- tryCatch(profile(model.zero), error=function(e){return("A")})
  low.z<-ifelse(is.character(model.zero)|is.character(profile.zero), NA, exp(confint(profile.zero, level=0.9))[2,1])
  hi.z<-ifelse(is.character(model.zero)|is.character(profile.zero), NA, exp(confint(profile.zero, level=0.9))[2,2])
  if(!is.na(low.c)&!is.na(hi.c)&!is.na(low.z)&!is.na(hi.z)){
    # combined confidence test @ 70% and 90% confidence
    pass <- ifelse(all(low.c*low.z<=1, hi.c*hi.z>=1), "Maybe?", "Confident")
    if (pass == "Maybe?"){
      low.c<- exp(confint(profile(model.count), level=0.7))[2,1]
      hi.c <- exp(confint(profile(model.count), level=0.7))[2,2]
      low.z<-exp(confint(profile(model.zero), level=0.7))[2,1]
      hi.z<-exp(confint(profile(model.zero), level=0.7))[2,2]
      pass <- ifelse(all(low.c*low.z<=1, hi.c*hi.z>=1), "Uncertain", "Likely")
    }
    # Get slope and intercept from hurdle
    model <- hurdle(y_var~x_var, dist=count_dist, zero.dist=zero_dist, link=link)
    fitted <- unname(model$fitted.values)
    slope <- round((fitted[length(fitted)] - fitted[1])/
                     (max(x_var) - min(x_var)),2)
    intercept <- round((fitted[1]-min(x_var)*((fitted[length(fitted)] - fitted[1])/
                                                (max(x_var) - min(x_var)))),2)
    years.for.trend <- sum(!is.na(y_var))
    output <- data.frame(slope=slope, intercept=intercept, CATTrend=pass,
                         years.for.trend=years.for.trend, test="Hurdle")
  }else{ # data can't be fitted
    output <- data.frame(slope=NA, intercept=NA, CATTrend=NA, years.for.trend=NA,
                         test="Hurdle")
  }
  return(output)
}


#--------------------------------------------------
#3) negbin_test
#'
#' @description
#' negbin fits a negative binomial model and returns multiple test statistics
#' given a variable y and a variable x.
#'
#' @param y_var a vector of numbers representing the y variable
#' @param x_var a vector of numbers representing the x variable
#'
#' @return a dataframe of the form || slope || intercept || ConfidenceLevel || Test type
#'
#' @details
#' The negbin function fits a negative binomial model to a sets of x and y variables
#' Confidence intervals are created to measure the level of confidence in the trend.
#' The slope and intercept of the resulting model are recorded and returned.
#' Things to take notice:
#' 1. y and x variables need to have the same length
#' 2. Theoretically saying, negbin is the most versatile among the three trend tests.
#'    The preferred condition to use negbin function is when there is neither an
#'    excess amount of zeros, nor can the trend be calculated by Mann-Kendall test.
#'    For those conditions, consider using the two other functions instead.
#'
#' @export
negbin_test <- function(y_var, x_var){
  model <- tryCatch(glm.nb(y_var~x_var), error=function(e){return("A")})
  profile.model <- tryCatch(profile(model), error=function(e){return("A")})
  low<-ifelse(is.character(model)|is.character(profile.model), NA, exp(confint(profile.model, level=0.9))[2,1])
  hi<-ifelse(is.character(model)|is.character(profile.model), NA, exp(confint(profile.model, level=0.9))[2,2])
  if (!is.na(low)&!is.na(hi)){
    # confidence test @ 70% and 90% confidence
    pass <- ifelse(all(low<=1, hi>=1), "Maybe?", "Confident")
    if (pass=="Maybe?"){
      low <- exp(confint(profile(model), level=0.7))[2,1]
      hi <-exp(confint(profile(model), level=0.7))[2,2]
      pass <- ifelse(all(low<=1, hi>=1),"Uncertain", "Likely")
    }
    # Get slope from negative binomial
    fitted <- unname(model$fitted.values)
    slope <- round((fitted[length(fitted)] - fitted[1])/
                     (max(x_var) - min(x_var)),2)
    intercept <- round((fitted[1]-min(x_var)*((fitted[length(fitted)] - fitted[1])/
                        (max(x_var) - min(x_var)))),2)
    years.for.trend <- sum(!is.na(y_var))
    output <- data.frame(slope=slope, intercept=intercept, CATTrend=pass,
                         years.for.trend=years.for.trend, test="Negative Binomial")
  }else{ # data can't be fitted
    output <- data.frame(slope=NA, intercept=NA, CATTrend=NA, years.for.trend=NA,
                         test="Negative Binomial")
  }
  return(output)
}


#--------------------------------------------------
### 4) Function to checks if a set of data is stationary based on if it is all 
###    zeros or the Wald-Wolfowitz test
##### Input:  var = list of numbers 
##### Output: data frame of the form: slope || intercept || ConfidenceLevel || 
#####                 years for trend || Test type

stationarity_test <- function(var){
  if (sum(var!=0)==0) { # tests don't work for only zeros, so single those out
    output <- data.frame(slope=0, intercept=mean(var, na.rm=TRUE), CATTrend="Confident",
                         years.for.trend=length(!is.na(var)), test="all zeros")
  } else {
    w_w <- ww.test(var)
    if (w_w$p.value>0.05 & !is.na(w_w$p.value)) { # only continue if null hypothesis is not rejected
      output <- data.frame(slope=0, intercept=mean(var, na.rm=TRUE), CATTrend="Confident",
                           years.for.trend=length(!is.na(var)), test="W-W")
    } else { 
      output <- data.frame(slope=NA, intercept=NA, CATTrend="Uncertain", 
                           years.for.trend=NA, test="W-W")
    }
  }
  return(output)
}


#--------------------------------------------------
### 5) Function to calculate trends using 3 tests; when possible a hurdle test 
### for those series with 3 or more zeros, then if possible a negative binomial 
### test, and finally a stationarity test
##### Input:  2 vectors of same length
#####           x_var = a list of numbers representing the x variable
#####           y_var = a list of numbers representing the y variable
##### Output: data frame of the form: HurdleChk || HurdleMes || NegBinChk ||
#####             NegBinMes || slope || intercept || ConfidenceLevel || 
#####             years for trend || Test type || slopes to map

identify_trends <- function(x_var, y_var) {
  # initialize data frame to accept messages
  test_res <- data.frame(HurdleChk=NA, HurdleMes=NA, NegBinChk=NA, NegBinMes=NA)

  # test if it is possible to use hurdle test
  hurdle <- FALSE #default to False
  if (sum(y_var==0) >= 3) { # minimum of 3 zero values needed to qualify for hurdle test
    # try to fit a hurdle model, with a letter as output if there is an error
    # or warning message
    model1 <- tryCatch(hurdle(y_var~x_var, data.frame(x_var=x_var, y_var=y_var), 
                       dist="negbin", zero.dist = "negbin"), error=function(e){return("A")},
                       warning=function(w){return("B")})
    # if the test runs, note the chi squared goodness-of-fit as HurdleChk
    if(!is.character(model1)){
      test_res$HurdleChk <- hurdletest(model1)[2,4]
      # if fit is good (smaller than 0.1), change flag to TRUE to use hurdle test
      if(!is.nan(test_res$HurdleChk)){ hurdle <- ifelse(test_res$HurdleChk>0.1, TRUE, FALSE) }
    # if test produces error or warning, note what the message as HurdleMes
    } else {
      test_res$HurdleMes <- tryCatch(hurdle(y_var~x_var, data.frame(x_var=x_var, 
                      y_var=y_var), dist="negbin", zero.dist = "negbin"), 
                      error=function(e){return(e$message)},
                      warning=function(w){return(w$message)})
    }
  }

  if(hurdle){
    #Apply the hurdle model
    message("Hurdle test")
    output <- hurdle_test(y_var, x_var)
    # if results are within 0.7 confidence interval, set flag back to FALSE
    if (output$CATTrend=="Uncertain" | is.na(output$CATTrend)) { hurdle <- FALSE}
  }  

  # if hurdle test wasn't appropriate or didn't provide conclusive results, test
  # if it is possible to use negative binomial test
  negbin <- FALSE #default to False
  if (!hurdle) {
    # try to fit a negative binomial model, with a letter as output if there is an error
    # or warning message
    model2 <- tryCatch(glm.nb(y_var~x_var), error=function(e){return("A")},
                       warning=function(w){return("B")})
    # if the test runs, note the chi squared goodness-of-fit as NegBinChk
    if (class(model2)[1]=="negbin"){
      test_res$NegBinChk <- pchisq(deviance(model2), df.residual(model2))
      # if fit is good (smaller than 0.1), change flag to TRUE to use negative binominal test
      if(!is.nan(test_res$NegBinChk)){ negbin <- ifelse(test_res$NegBinChk>0.1, TRUE, FALSE) }
    } else {
      # if test produces error, note what the message as NegBinMes
      if (model2=="A") {
        test_res$NegBinMes <- tryCatch(glm.nb(y_var~x_var), 
                                     error=function(e){return(e$message)})
      }
    # if test produces warning, note what the message as NegBinMes
      if (model2=="B") {
        test_res$NegBinMes <- tryCatch(glm.nb(y_var~x_var),
                                    warning=function(w){return(w$message)})
        # run the negative binomial model again to get output in addition to warning message
        model2 <- glm.nb(y_var~x_var)
        # note the chi squared goodness-of-fit as NegBinChk
        test_res$NegBinChk <- pchisq(deviance(model2), df.residual(model2))
        # if fit is good (smaller than 0.1), change flag to TRUE to use negative binominal test
        if(!is.nan(test_res$NegBinChk)){ negbin <- ifelse(test_res$NegBinChk>0.1, TRUE, FALSE) }
        # if the warning message is anything else than "iteration limit reached", (or french equivalent) change flag back to FALSE
        if (!any(grepl("iteration limit reached",test_res$NegBinMes), 
            grepl("nombre limite d'iterations atteint",test_res$NegBinMes))) {
          negbin <- FALSE
        }
      }
    }
  }
  
  if (negbin) {
    #Apply the negative binomial model
    message("Negative Binomial test")
    output <- negbin_test(y_var, x_var)
    # if results are within 0.7 confidence interval, set flag back to FALSE
    if (output$CATTrend=="Uncertain" | is.na(output$CATTrend)) { negbin <- FALSE}
  }
  
  # test for stationarity for those stations where neither hurdle nor negative
  # binomial worked
  if (!hurdle & !negbin) {
    message("testing for stationarity")
    output <- stationarity_test(y_var)
  }
  
  # merge the messages with the output
  output <- merge(test_res,output)
  # create a field of slopes to map for those stations where we have confidence
  # in the calculated slopes
  output$mapslope <- case_when(grepl("Likely", output$CATTrend)    ~ output$slope,
                               grepl("Confident", output$CATTrend) ~ output$slope)
  return(output)
}

#-------------------------------------------------------------------------------
### 6) Function to identify potential outliers using Rosner's test and confirm
### true outliers using percentage of non-zero values and Pettitt's change test.
### Also creates a pdf file to graphically display results.
##### Input:  4 vectors of same length with trend information (with one entry per station):
#####               tr.stn = STATION_NUMBER
#####               tr.slope = slope of calculated trend (usually mapslope to keep only confident and likely slopes)
#####               tr.int = intercept of calculated trend,
#####               tr.test = type of test used to calculate trend
#####         3 vectors of same length with data used to calculate trends (with many entries per station, one for each year)
#####               data.stn = STATION_NUMBER
#####               data.yr = year for which statistic is calculated
#####               data.val = value of statistic (usually low or high flow days)
##### Output: list with index number of confirmed outliers

find_outliers <- function(tr.stn, tr.slope, tr.int, tr.test, data.stn, data.yr, 
                          data.val, start.yr, end.yr, file.name) {
  
  # build data frames
  trend <- data.frame(stn=tr.stn, slope=tr.slope, intercept=tr.int, test=tr.test)
  data <- data.frame(stn=data.stn, year=data.yr, value=data.val)
  
  # determine potential outliers in trends with Rosner's test. Number of outliers
  # to be tested is 2.5% of number of values in data. This step always generates an
  # warning message because method wasn't tested for large data sets but it
  # shouldn't be a problem
  result.rosner <- rosnerTest(tr.slope, k = as.integer(round(0.025*sum(!is.na(tr.slope)))))
  listValue <- result.rosner$all.stats$Value[result.rosner$all.stats$Outlier]
  listIndex <- result.rosner$all.stats$Obs.Num[result.rosner$all.stats$Outlier]
  message(paste(length(listIndex), "potential outliers in trends identified"))
  
  # create pdf file with graphs to be able to check results
  pdf(file = paste0("./Output/", file.name, ".pdf"), width = 8.5, height = 11)
  par(mfrow = c(4,3))
  
  # plot data to show potential outliers as identified with Rosner's test
  n <- sum(!is.na(trend$slope))
  col=rep("black",n)
  col[which(sort(trend$slope[!is.na(trend$slope)]) %in% listValue)] <- "orange"
  plot(1:n,sort(trend$slope[!is.na(trend$slope)]), col=col, xlab=NA, ylab="trends")
  title(main=paste0("Potential outliers (",length(listIndex),")"))
  legend("topleft", legend=c("data", "outlier"), pch=1, col=c("black", "orange"), cex=0.8)
  
  # initialize list to compile confirmed outliers
  output <- c()
  
  # define the features of graphs that will be the same for each station
  x <- start.yr:end.yr
  leg.sym <- c(1, 8)
  leg.obj <- c("drought days", "insufficient data")
  leg.col <- c("black", "red")
  par(mar=c(5.1, 4.1, 3.6, 2.1))

  # for each potential outlier in trend
  for (m in 1:length(listIndex)) {
    message(paste("Station", trend$stn[listIndex[m]]))
    
    # get station data used to calculate trend
    stn <- data[data$stn==trend$stn[listIndex[m]],]
    stn <- stn[stn$year %in% start.yr:end.yr,]
    # plot data with original slope
    plot(stn$value ~ stn$year, xlim=c(start.yr,end.yr), xlab="year", ylab="data values")
    # include years with no values as different symbols
    if (sum(is.na(stn$value))>0) {
      not <- is.na(stn$value)
      points(stn$year[which(not)], rep(0, sum(not)), pch=8, col="red")
    }
    title(main=paste0(listIndex[m], " - ", trend$stn[listIndex[m]]), line=2.5, cex=1.2)
    lines(x, as.numeric(trend$slope[listIndex[m]])*x+as.numeric(trend$intercept[listIndex[m]]), 
          col="blue")
    mtext(paste0("Calculated trend: ",trend$test[listIndex[m]], " test - slope: ", 
          trend$slope[listIndex[m]]), side=3, line=1.5, adj=0, cex=0.5, col="blue")
    legend("topright", legend=leg.obj, pch=leg.sym, col=leg.col, cex=0.8)

    # remove NA values in data
    if (sum(is.na(stn$value))>0) { stn <- stn[-which(is.na(stn$value)),] }
    
    # identify outliers that have less than or equal to 10% of non-zero values
    if (sum(stn$value!=0)/length(stn$value) <= 0.1) {
      output <- append(output, listIndex[m])
      mtext("Identified as outlier because too few non-zero values", 
            side=3, line=0.5, adj=0, cex=0.5, col="blueviolet")
    }
    
    # for those not classified as outliers with first test, use pettitt test to
    # identify outliers that have a sharp change during time series
    if (!listIndex[m] %in% output) {
      result.pettitt <- pettitt.test(stn$value)
      if (result.pettitt$p.value < 0.05) {
        output <- append(output, listIndex[m])
        mtext("Identified as outlier because sharp change in time series", 
            side=3, line=0.5, adj=0, cex=0.5, col="blueviolet")
      }
    }
    
  } # close loop cycling through all m values of listIndex
    
  dev.off()
  
 return(output)
}

#-------------------------------------------------------------------------------
### 7) Function to plot data and trends for specific example stations, as well as 
### calculate average values in the 1970s and in the 2010s.
##### Input:  stn.list = list of alphanumeric station numbers
#####         tr.type = text, describing the type of trend
#####         3 vectors of same length calculated trends (with one entry per station)
#####               tr.stn = STATION_NUMBER
#####               tr.slope = slope of calculated trend (usually mapslope to keep only confident and likely slopes)
#####               tr.int = intercept of calculated trend,
#####         3 vectors of same length with data used to calculate trends (with many entries per station, one for each year)
#####               data.stn = STATION_NUMBER
#####               data.yr = year for which statistic is calculated
#####               data.val = value of statistic (usually low or high flow days)
##### Output: series of plots with graph and stats printed on the graph. The plots
#####         are added to a location already open before the function is called
#####         or they appear in the window

ex_stn_trend_stats <- function(stn.list, tr.type, tr.stn, tr.slope, tr.int, 
                            data.stn, data.yr, data.val) {

  tr <- data.frame(STATION_NUMBER=tr.stn, slope=tr.slope, intercept=tr.int)
  data <- data.frame(STATION_NUMBER=data.stn, year=data.yr, value=data.val)

  x <- 1970:2021

  par(mar = c(4, 4, 3, 1))
  for (j in 1:length(stn.list)) {
    stn <- stn.list[j]
    name <- hy_stations(stn) %>% pull(STATION_NAME)
    # separate out data for that station
    d <- data %>% filter(STATION_NUMBER==stn) %>% na.omit()
    trend <- tr[tr$STATION_NUMBER==stn,]

        # calculate decadal averages for 1970s and 2010s
    M70 <- d %>% filter(year %in% seq(1970,1979)) %>% pull(value)
    M70 <- mean(M70,na.rm=TRUE)
    M10 <- d %>% filter(year %in% seq(2010,2019)) %>% pull(value)
    M10 <- mean(M10,na.rm=TRUE)
    
    # plot data
    plot(d$year, d$value, xlim=c(1970,2021), xlab="year", ylab="values",
         mgp=c(1.5, 0.5, 0))
    if (sum(is.na(data$dr_days))>0) {
      not <- is.na(data$dr_days)
      points(data$year[which(not)], rep(0, sum(not)), pch=8, col="red")
    }
    title(main=paste(stn, tr.type, "trend"), cex.main=0.8, line=2)
    title(main=name, cex.main=0.6, line=1.2)
    # plot trend slope
    lines(x, as.numeric(trend$slope)*x+as.numeric(trend$intercept), col="blue")
    title(main=paste("trend of", format(trend$slope), "values/year"), line=0.5, 
          cex.main=0.6, col.main="blue")
    # plot decadal averages
    lines(x=c(1970,1979), y=c(M70,M70), col="blueviolet", lwd=2)
    text(x=1970, y=0.95*max(d$value), paste0("1970s\n",format(M70)), adj=0, 
         cex=0.7, col="blueviolet")
    lines(x=c(2010,2019), y=c(M10,M10), col="blueviolet", lwd=2)
    text(x=2010, y=0.95*max(d$value), paste0("2010s\n",format(M10)), adj=0, 
         cex=0.7, col="blueviolet")
  }
}
